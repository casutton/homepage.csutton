<ul class="biblist">
        
	
        
	<li class="bibitem">






<p>



<a href=""><b>A Survey of Machine Learning for Big Code and Naturalness</b></a>.&nbsp;Miltiadis Allamanis, Earl T. Barr, Premkumar Devanbu and Charles Sutton.
   <i>ACM Computing Surveys</i> 51 (4).
  
  2018.





</p>




<p>
   [
  
     
		 
		 <a href="https://arxiv.org/pdf/1709.06182.pdf">arXiv</a>
  
  
     | <a href="javascript:toggle('bibbig-code-survey', 'bib_link_big-code-survey', 'bib')"  id="bib_link_big-code-survey">bib</a>
     
   
   
   
	 
	 
   ]
</p>



<div id="divbig-code-survey"></div>
<div style="display:none;" id="absbig-code-survey"><div class="abstract"></div></div>

<div style="display:none;" id="bibbig-code-survey"><pre class="bibtex">@article{big-code-survey,
  author = {Allamanis, Miltiadis and Barr, Earl T. and Devanbu, Premkumar and Sutton, Charles},
  journal = {ACM Computing Surveys},
  month = {sep},
  number = {4},
  title = {A Survey of Machine Learning for Big Code and Naturalness},
  volume = {51},
  year = {2018}
}
</pre></div>


</li>
        
	
        
	<li class="bibitem">






<p>



<a href="publications/avitm.pdf"><b>Autoencoding Variational Inference for Topic Models</b></a>.&nbsp;Akash Srivastava and Charles Sutton.
	In <i>International Conference on Learning Representations (ICLR)</i>.  2017.





</p>




<p>
   [
  
     <a href="publications/avitm.pdf">.pdf</a>
		  | 
		 <a href="https://arxiv.org/abs/1703.01488">arXiv</a>
  
  
     | <a href="javascript:toggle('bibsrivastava17lda', 'bib_link_srivastava17lda', 'bib')"  id="bib_link_srivastava17lda">bib</a>
     
   
   
        | <a href="https://openreview.net/forum?id=BybtVK9lg">discussion</a>
   
   
        | <a href="https://github.com/akashgit/autoencoding_vi_for_topic_models">source code</a>
   
	 
	 
   ]
</p>



<div id="divsrivastava17lda"></div>
<div style="display:none;" id="abssrivastava17lda"><div class="abstract"></div></div>

<div style="display:none;" id="bibsrivastava17lda"><pre class="bibtex">@inproceedings{srivastava17lda,
  author = {Srivastava, Akash and Sutton, Charles},
  booktitle = {International Conference on Learning Representations (ICLR)},
  title = {Autoencoding Variational Inference for Topic Models},
  year = {2017}
}
</pre></div>


</li>
        
	
        
	<li class="bibitem">






<p>



<a href="https://arxiv.org/abs/1705.07761"><b>VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning</b></a>.&nbsp;Akash Srivastava, Lazar Valkov, Chris Russell, Michael Gutmann and Charles Sutton.
	In <i>Advances in Neural Information Processing Systems (NIPS)</i>.  2017.





</p>




<p>
   [
  
     <a href="https://arxiv.org/abs/1705.07761">.pdf</a>
		 
		 
  
  
     | <a href="javascript:toggle('bibsrivastava17veegan', 'bib_link_srivastava17veegan', 'bib')"  id="bib_link_srivastava17veegan">bib</a>
     
       | <a href="javascript:toggle('abssrivastava17veegan', 'abs_link_srivastava17veegan', 'abstract')" id="abs_link_srivastava17veegan">abstract</a>
     
   
   
   
	 
	 
        | <a href="https://akashgit.github.io/VEEGAN/">code and data</a>
   
   ]
</p>



<div id="divsrivastava17veegan"></div>
<div style="display:none;" id="abssrivastava17veegan"><div class="abstract">Deep generative models provide powerful tools for distributions over complicated manifolds, such as those of natural images. But many of these methods, including generative adversarial networks (GANs), can be difficult to train, in part because they are prone to mode collapse, which means that they characterize only a few modes of the true distribution. To address this, we introduce VEEGAN, which features a reconstructor network, reversing the action of the generator by mapping from data to noise. Our training objective retains the original asymptotic consistency guarantee of GANs, and can be interpreted as a novel autoencoder loss over the noise. In sharp contrast to a traditional autoencoder over data points, VEEGAN does not require specifying a loss function over the data, but rather only over the representations, which are standard normal by assumption. On an extensive set of synthetic and real world image datasets, VEEGAN indeed resists mode collapsing to a far greater extent than other recent GAN variants, and produces more realistic samples.</div></div>

<div style="display:none;" id="bibsrivastava17veegan"><pre class="bibtex">@inproceedings{srivastava17veegan,
  author = {Srivastava, Akash and Valkov, Lazar and Russell, Chris and Gutmann, Michael and Sutton, Charles},
  booktitle = {Advances in Neural Information Processing Systems (NIPS)},
  title = {VEEGAN: Reducing Mode Collapse in GANs using Implicit Variational Learning},
  year = {2017}
}
</pre></div>


</li>
        
	
        
	<li class="bibitem">






<p>



<a href="publications/crftut-fnt.pdf"><b>An Introduction to Conditional Random Fields</b></a>.&nbsp;Charles Sutton and Andrew McCallum.
   <i>Foundations and Trends in Machine Learning</i> 4 (4).
  
  2012.





</p>




<p>
   [
  
     <a href="publications/crftut-fnt.pdf">.pdf</a>
		 
		 
  
  
     | <a href="javascript:toggle('bibcrftut:fnt', 'bib_link_crftut:fnt', 'bib')"  id="bib_link_crftut:fnt">bib</a>
     
       | <a href="javascript:toggle('abscrftut:fnt', 'abs_link_crftut:fnt', 'abstract')" id="abs_link_crftut:fnt">abstract</a>
     
   
   
   
	 
	 
   ]
</p>



<div id="divcrftut:fnt"></div>
<div style="display:none;" id="abscrftut:fnt"><div class="abstract">Often we wish to predict a large number of variables that depend on each other as well as on other observed variables. Structured prediction methods are essentially a combination of classification and graphical modeling, combining the ability of graphical models to compactly model multivariate data with the ability of classification methods to perform prediction using large sets of input features. This tutorial describes conditional random fields, a popular probabilistic method for structured prediction. CRFs have seen wide application in natural language processing, computer vision, and bioinformatics. We describe methods for inference and parameter estimation for CRFs, including practical issues for implementing large scale CRFs. We do not assume previous knowledge of graphical modeling, so this tutorial is intended to be useful to practitioners in a wide variety of fields.</div></div>

<div style="display:none;" id="bibcrftut:fnt"><pre class="bibtex">@article{crftut:fnt,
  author = {Sutton, Charles and McCallum, Andrew},
  journal = {Foundations and Trends in Machine Learning},
  number = {4},
  pages = {267â€“373},
  title = {An Introduction to Conditional Random Fields},
  volume = {4},
  year = {2012}
}
</pre></div>


</li>
        
	
</ul>
